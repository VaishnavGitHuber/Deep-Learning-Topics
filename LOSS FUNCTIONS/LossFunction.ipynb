{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### LOSS FUNCTION\n",
        "* The loss function is a method of evaluating how well your machine learning algorithm models your featured data set. In other words, loss functions are a measurement of how good your model is in terms of predicting the expected outcome.\n",
        "The Most commonly used LossFunctions are,\n",
        "1. MAE(Mean Absolute error)\n",
        "2. MSE(Mean squared error)\n",
        "3. Binary cross entropy\n",
        "4. Categorical cross entropy\n",
        "5. sparse categorical cross entropy\n",
        "* We are trying to implement the MAE,MSE,Binary croos entropy\n"
      ],
      "metadata": {
        "id": "Vz5O-GPDQn4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "tqb6eZ16SZwU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEAN ABSOLTE ERROR"
      ],
      "metadata": {
        "id": "ESao46UeSQv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2m4RjoCdQRgQ"
      },
      "outputs": [],
      "source": [
        "# Let, y_true be the actual values and y_pred are the predicted values\n",
        "y_true = [23.5,67.9,99.7,25.6,88.9]\n",
        "y_pred = [21.5,61.8,95,23.2,80.7]\n",
        "\n",
        "def mae(y_true,y_pred):\n",
        "  total_error = 0\n",
        "  for yt,yp in zip(y_true,y_pred):\n",
        "    total_error += abs(yt-yp)\n",
        "  print(\"Total error: \",total_error)\n",
        "  print(\"MAE: \",total_error/len(y_true))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae(y_true,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpN9akhZSE_Q",
        "outputId": "e0be39bc-c4b2-4e3e-98a8-16d126e75aa7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total error:  23.400000000000016\n",
            "MAE:  4.680000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEAN SQUARED ERROR"
      ],
      "metadata": {
        "id": "-hRoPPeRSVk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now tets do MSE(Mean squared error)\n",
        "y_true = [23.5,67.9,99.7,25.6,88.9]\n",
        "y_pred = [21.5,61.8,95,23.2,80.7]\n",
        "\n",
        "def mse(y_true,y_pred):\n",
        "  total_error = 0\n",
        "  for yt,yp in zip(y_true,y_pred):\n",
        "    total_error += np.square(abs(yt-yp))\n",
        "  print(\"Total error: \",total_error)\n",
        "  print(\"MSE: \",total_error/len(y_true))"
      ],
      "metadata": {
        "id": "zilFUEx6SUsg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(y_true,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJS-ISGSyy0",
        "outputId": "eae330e4-451e-485d-ae04-7043e64b96e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total error:  136.30000000000018\n",
            "MSE:  27.260000000000037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY CROSS ENTROPY"
      ],
      "metadata": {
        "id": "jv0V3LE1TJWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let this is actual value and y_pred is the predicted value\n",
        "y_true = [0,1,1,0,0,1]\n",
        "y_pred = [1,1,1,0,1,0]\n",
        "\n",
        "def binary_cross_entropy(y_pred,y_true):\n",
        "  epsilon = 1e-15\n",
        "  y_pred_new = [max(i,epsilon) for i in y_pred]\n",
        "  y_pred_new = [min(i,1-epsilon) for i in y_pred_new]\n",
        "  total_logloss = 0\n",
        "  for yt,yp in zip(y_true, y_pred_new):\n",
        "    total_logloss += yt * np.log(yp) + (1-yt) * np.log(1-yp)\n",
        "  logloss = -1 * (total_logloss) / len(y_true)\n",
        "  print(\"Binary cross entropy/Logloss: \",logloss)"
      ],
      "metadata": {
        "id": "6BoQsdMwS5He"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cross_entropy(y_true,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Djwcz1UTEhk",
        "outputId": "f856c583-a779-45fa-c7f0-03f8dd9940c8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary cross entropy/Logloss:  17.269521463693707\n"
          ]
        }
      ]
    }
  ]
}